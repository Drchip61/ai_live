# 模块介绍
当前文档专注于介绍目前对本地记忆机制以及其它相关机制的设计介绍。首先明确一点，目前所做的记忆组件专注于记忆主播以及直播的状态，暂时不需要专注于记忆有关用户个人的细节和信息。以后可能会扩展或者引入其它模块来处理更细致的长期记忆，但当前的机制不需要考虑它。

# 记忆分层
此次记忆机制的核心在于分层设计，每一层都有自己的记忆和遗忘机制。
## active
最短期的记忆，会在每次主播生成回复后添加
### 来源机制
主播每次生成回复后，当前回复内容以及其完整上下文会被小型语言模型总结成一条第一人称的记忆。注意，总结记忆的后处理必须异步运行，不能增加主播回复的延迟。
### 遗忘机制
总容量固定且可设置，First In First Out。被挤出的旧记忆会被移入temporary层。
### 取回机制
无需RAG取回，它会作为被总结过的消息历史直接通过时序加入生成上下文
## temporary
进入RAG流程的短期记忆
### 来源机制
所有active层的记忆在因超出上限被挤出时都会被直接加入这一层。
### 遗忘机制
没有硬性上线，每一条记忆都有个重要性评分significance，取值为0-1之间，取小数点后三位。重要性低于固定值的记忆会被删除。significance的增加和减少方法需要被单独拿出来作成个函数方便日后修改，算法暂时定为：每次RAG取回后，所有未被取用的记忆significance乘以特定可调系数衰减，每次被取过的记忆significance与1之间的差值缩减一半。
### 取回机制
通过RAG取回。根据时间戳自动计算出记忆所属的相对时间并插入到该条目的前面，例如“【1分34秒之前的记忆】”
## summary
定时总结的中长期记忆
### 来源机制
每经过特定的自然时间（暂定5分钟，可调）自动触发。自动汇总当前时间段的浅层记忆，弹幕和最新发言（以及未来可能加入的其它模块的背景数据）对整个时间段的记忆进行总结。
### 遗忘机制
每条记忆significance值，significance的增加和衰减机制与temporary层一致，但是涉及到的参数另外单独取值。每当特定时间经过（暂定10分钟，可调），将特定比例（暂定1%向下取整，可调）的significance最低的记忆删除
### 取回机制
通过RAG取回。根据时间戳自动计算出记忆所属的相对时间段并插入到该条目的前面，根据结束时间，单位只给到分钟即可，例如“【25分前的记忆】”
## static
写死的预设记忆，可能是有关人物的背景设定和背景回忆。
### 来源机制
写在对应角色./personas/{角色名}/static_memories文件夹里的json文件中，在记忆初始化时自动读入。
### 遗忘机制
不会被遗忘
### 取回机制
通过RAG取回。根据固定记忆json文件里提供的category加上前缀，category暂定重置为：
```
"identity": "【关于我自己的回忆】"
"relationship": "【关于我认识的其他人的回忆】"
"experience": "【让我联想起自己过去的回忆】"
"personality": "【我对此的本能感觉与反应】"
"world": "【我所知道的相关知识】"
```
注意，以上只是写明了category对前缀的对应关系，并不是储存形式。category的定义应当被储存在单独的json文件里，每个category可能会包含其它类别的相关信息，方便以后添加和编辑。
# 已删除的记忆
已删除的记忆以及相关数据会被储存在./personas/{角色}/archived_memories里面的一个json文件里，不会再被取用。

# 关于取回机制的总体设定
对于取回基于RAG的记忆时，做一个单独的类出来方便日后修改算法。例如，目前对于跨层级的取回数量，有两种方案：
- 每一层分配一个定额，基于每个层级选择最高相似度的几条。定额可调整。
- 所有层级一起取回，但每条记忆所属的层级会影响它们的分值，给分值乘以对应层级的系数（系数可调整）。chroma本身应该不支持内置这种加权取回，所以可以考虑根据常规方法多取回一些（数量倍数可调整），再进行加权运算和重新排列。

当不同层级的回忆被RAG取回时，在被加入prompt前，需要满足排列方式：层级从短到长排列；相同层级内时间从近到远排列。

# 备注
以上提到的所有可以调整的常量需要被汇总在一起方便日后调整和测试。
关于所有机制的触发条件（根据RAG的call而触发/根据自然时间流逝而触发/根据当前层级添加了新记忆而触发）需要做成模块化的形式，给以后留下切换的空间。