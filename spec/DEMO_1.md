## 主要计划
本项目的目的在于给LLM制作一个wrapper，将其置身于一个虚拟在线直播间的环境，并针对性做出优化，让它能在这个情况下做出优质的回答。本项目主要使用python及其各式运行库，命名法采用snake case，默认缩进为2格。本项目的文书和注释都应该以中文为准。
#### 路径标准
计划中出现的一切文件路径都以名mio-straming-demo的基础文件夹为根目录，例如./spec便是mio-straming-demo文件夹下的spec文件夹。假如指示中，或者工作流程中涉及到不存在的文件夹，那就将其创建。
### 模块设计
- ./secrets/ 这是个包含在gitignore中的文件夹，里面会包含一些类似api_key之类不便透露但又需要用到的信息。当你需要用到类似数据时可以在secrets中创建对应的空文件并假定它会被添加进来
- ./langchain_wrapper/ 这个文件夹中的内容会调用langchain库并与目标模型进行交互。其中包含几层：一个可以随时在远程openai api和本地小型qwen模型之间切换的模型源（为了保证接口类型一致可以考虑使用vllm来包装本地qwen）；在这之上一个langchain的管道，可以在其中加入一些langchain自带或自定义的前处理或后处理工具；在这之上，将整个管道打包成一个简单的wrapper交给更前端的虚拟环境调用。
- ./streaming_studio/ 在langchain_wrapper2之上的层级，一个抽象化的虚拟直播间。需要做到异步运行，即便外部不传入任何操作它本身也依旧在运行着。有两个主要的公用方法，一个是send_comment()在任何时间传入单条的直播间的实时评论（弹幕），包含用户名，时间戳，来源（抽象键值）等元信息。一个是get_response()可能在任何时间返回主播回复的输出方法。所有传入的弹幕都需要被记录在一个数据库里。目前阶段，请选择一个简易的本地数据库运行库来应用这部分。在这个文件夹下，同时创建一个单独的文件test_chatter_studio.py，当中包含一个专门用来测试的类TestChatterStudio，让它可以立刻开启一个直播间的实例，并调用send_comment和get_response让单个固定的用户与之交互（在测试开始时让使用者设定自己扮演的用户的基础信息，目前包括：用户id，用户昵称），并以一个简单的命令行聊天界面展现。
- ./prompts/ 包含一系列txt文件。langchain中需要用到的提示词都会储存在这里。langchain_wrapper中应该专门定义一个特殊的PromptLoader类来加载这里的提示词，方便运行中读取。不同部分的提示词需要分开存储，比方说扮演主播的基础指令，当前主播的具体人设（编出3个不同的人物预设作为占位，允许在PromptLoader里根据特殊方法的参数来选择）
- ./connection/ 创建一个用于与未知前端进行异步交互的简易自定义类StreamServiceHost。使用websocket库，做到：可以分别让数量不等的输入者和输出者订阅。任何输入者传来的虚拟直播弹幕会被发向streaming_studio层级，而任何streaming_studio返回的主播回复会被推送给所有的输出者。在这个文件夹下，同时创建一个单独的文件test_chatter_web.py，当中包含一个专门用来测试的类TestChatterWeb，可以同时以输入者和输出者的身份分别订阅在本地运行的StreamServiceHost服务，并以一个简单的命令行聊天界面展现，让开发者使用
### 工作指示
./spec文件夹中是用户的指示，永远不要改动./spec文件夹中的内容。
工作开始后，你应当先对该项目的目标做出解读，并且理解我所需要达成的目标，并在./plan文件夹中对每一个模块写下一个.md文件作为之后工作的计划，分类包含你想要做的步骤和已经实现的步骤。已有的计划文件可以被更改用以解释并进一步计划你的工作。
### 步骤指示
这一段代表着项目目前在什么阶段。
当前阶段：草稿，目标是首先搭起这个框架，代码和注释尽可能做到简洁，可读，不要插入非必要的注释。不要考虑生产环境下的工业化部署需求。对于并未完全说明应用方法的部分，将其尽可能空置，维持在不影响其它部分的程度。